Here's a **complete `README.md` file** for your `QA_System` project based on what you've shared (Gemini integration, document-based QA using Streamlit and LlamaIndex):

---

````markdown
# QA_System üß†üìÑ  
**Question Answering System using Gemini and LlamaIndex**

This is a document-based QA system that lets you upload your PDF and ask natural language questions to extract information from it. It uses **Gemini (Google's LLM)** as the backend, along with **LlamaIndex** for indexing and querying the document. The frontend is built using **Streamlit**.

---

## üöÄ Features

- ‚úÖ Upload PDF documents
- ‚úÖ Ask natural language questions
- ‚úÖ Uses Gemini Pro (`gemini-1.5-flash-latest`) as the LLM
- ‚úÖ Indexes documents using LlamaIndex
- ‚úÖ Clean, minimal Streamlit interface

---

## üß∞ Tech Stack

- **Python 3.8+**
- **Streamlit**
- **LlamaIndex**
- **Gemini LLM via Google Generative AI**
- **dotenv (for secrets handling)**

---

## üì¶ Installation

### 1. Clone the repository

```bash
git clone https://github.com/Jagritimaurya82/QA_SYSTEM.git
cd QA_SYSTEM
````

### 2. Create a virtual environment (optional but recommended)

```bash
python -m venv venv
source venv/bin/activate  # or venv\Scripts\activate on Windows
```

### 3. Install dependencies

```bash
pip install -r requirements.txt
```

---

## üîë Setup API Keys

Create a `.env` file in the root directory and add your Gemini API key:

```env
GOOGLE_API_KEY=your_gemini_api_key_here
```

> You can get your Gemini API key from [Google AI Studio](https://makersuite.google.com/app).

---

## ‚ñ∂Ô∏è Run the App

```bash
streamlit run StreamlitApp.py
```

The app will open in your default browser.

---

## üóÉÔ∏è Project Structure

```
QA_SYSTEM/
‚îú‚îÄ‚îÄ app.py                      # Streamlit UI
‚îú‚îÄ‚îÄ requirements.txt
‚îú‚îÄ‚îÄ .env                        # Gemini API Key (not committed)
‚îú‚îÄ‚îÄ logs/                       # App logs
‚îú‚îÄ‚îÄ Data/                       # Folder where PDFs are uploaded
‚îú‚îÄ‚îÄ QAWithPDF/
‚îÇ   ‚îú‚îÄ‚îÄ data_ingestion.py      # Loads and parses PDFs
‚îÇ   ‚îú‚îÄ‚îÄ embedding.py           # Embeds documents using Gemini + LlamaIndex
‚îÇ   ‚îú‚îÄ‚îÄ model_api.py           # Loads the Gemini model
‚îú‚îÄ‚îÄ exception.py               # Custom exception handler
‚îú‚îÄ‚îÄ logger.py                  # Logging setup
```

---

## üì∏ Screenshots

![screenshot1](screenshots/upload.png)

> Upload document

![screenshot2](screenshots/qa.png)

> Ask questions and get accurate answers

---

## ‚ö†Ô∏è Note

* Only PDF file support is implemented.
* Gemini LLMs require internet and valid API key.
* Model used: `gemini-1.5-flash-latest` (changeable in `model_api.py`)

---
 
